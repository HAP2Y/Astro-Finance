{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YavSeQpGOvhpIqQnllxN3dF4t9j-QLZI",
      "authorship_tag": "ABX9TyPb3v5xDZzi9Ssk5sKTi0+9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HAP2Y/Astro-Finance/blob/main/AstroFinanceProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install all required libraries\n",
        "!pip install yfinance tabulate\n",
        "\n",
        "# Step 2: Import all necessary libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from tabulate import tabulate\n",
        "import time # Library for adding the \"polite wait\"\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "# REVISED & EXPANDED dictionary focusing on Indian and US markets.\n",
        "TICKER_INFO = {\n",
        "    # --- Indian Markets (Indices) ---\n",
        "    '^NSEI':                {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY 50\n",
        "    '^NSEBANK':             {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY BANK\n",
        "    'NIFTY_FIN_SERVICE.NS': {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY FINANCIAL SERVICES\n",
        "    '^CNXIT':               {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY IT\n",
        "    '^CNXPHARMA':           {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY PHARMA\n",
        "    '^CNXAUTO':             {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY AUTO\n",
        "    '^CNXMETAL':            {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY METAL\n",
        "    '^CNXFMCG':             {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY FMCG\n",
        "    '^INDIAVIX':            {'currency': 'INR', 'volume_unit': 'points'}, # India VIX\n",
        "\n",
        "    # --- Indian Markets (Key Stocks) ---\n",
        "    'RELIANCE.NS':          {'currency': 'INR', 'volume_unit': 'shares'}, # Reliance Industries\n",
        "    'TCS.NS':               {'currency': 'INR', 'volume_unit': 'shares'}, # Tata Consultancy Services\n",
        "    'HDFCBANK.NS':          {'currency': 'INR', 'volume_unit': 'shares'}, # HDFC Bank\n",
        "\n",
        "    # --- US Markets (Indices) ---\n",
        "    '^GSPC':        {'currency': 'USD', 'volume_unit': 'points'}, # S&P 500\n",
        "    '^DJI':         {'currency': 'USD', 'volume_unit': 'points'}, # Dow Jones Industrial Average\n",
        "    '^NDX':         {'currency': 'USD', 'volume_unit': 'points'}, # NASDAQ 100\n",
        "    '^RUT':         {'currency': 'USD', 'volume_unit': 'points'}, # Russell 2000 (Small-Cap)\n",
        "    '^VIX':         {'currency': 'USD', 'volume_unit': 'points'}, # CBOE Volatility Index\n",
        "    '^TNX':         {'currency': 'USD', 'volume_unit': 'points'}, # US 10-Yr Treasury Yield\n",
        "\n",
        "    # --- US Markets (Key Stocks) ---\n",
        "    'AAPL':         {'currency': 'USD', 'volume_unit': 'shares'}, # Apple Inc.\n",
        "    'MSFT':         {'currency': 'USD', 'volume_unit': 'shares'}, # Microsoft Corp.\n",
        "    'NVDA':         {'currency': 'USD', 'volume_unit': 'shares'}, # NVIDIA Corp.\n",
        "\n",
        "    # --- Global Markets (Indices) ---\n",
        "    '^N225':        {'currency': 'JPY', 'volume_unit': 'points'}, # Nikkei 225 (Japan)\n",
        "    '^FTSE':        {'currency': 'GBP', 'volume_unit': 'points'}, # FTSE 100 (UK)\n",
        "    '^GDAXI':       {'currency': 'EUR', 'volume_unit': 'points'}, # DAX (Germany)\n",
        "    '000001.SS':    {'currency': 'CNY', 'volume_unit': 'shares'}, # SSE Composite (Shanghai)\n",
        "    '^HSI':         {'currency': 'HKD', 'volume_unit': 'points'}, # Hang Seng (Hong Kong)\n",
        "\n",
        "    # --- Commodities ---\n",
        "    'GC=F':         {'currency': 'USD', 'volume_unit': 'contracts'}, # Gold\n",
        "    'CL=F':         {'currency': 'USD', 'volume_unit': 'contracts'}, # Crude Oil\n",
        "    'SI=F':         {'currency': 'USD', 'volume_unit': 'contracts'}, # Silver\n",
        "\n",
        "    # --- Currencies & DXY ---\n",
        "    'DX-Y.NYB':     {'currency': 'USD', 'volume_unit': 'points'},    # US Dollar Index\n",
        "    'USDINR=X':     {'currency': 'INR', 'volume_unit': 'rate'},\n",
        "    'EURUSD=X':     {'currency': 'USD', 'volume_unit': 'rate'},\n",
        "}\n",
        "\n",
        "TICKERS = list(TICKER_INFO.keys())\n",
        "START_DATE = '2000-01-01'\n",
        "END_DATE = datetime.now().strftime('%Y-%m-%d') # Automatically set end date to today\n",
        "OUTPUT_FILENAME_PREFIX = 'financial_data'\n",
        "WAIT_TIME_SECONDS = 2 # The \"polite wait\" time between API calls\n",
        "\n",
        "# List to store summary results for final verification\n",
        "results_summary = []\n",
        "\n",
        "# --- Main Script: Acquire, Save, and Verify ---\n",
        "\n",
        "print(f\"üöÄ Starting long-term data acquisition from {START_DATE} to {END_DATE}...\")\n",
        "print(f\"Total tickers to process: {len(TICKERS)}\")\n",
        "\n",
        "for i, ticker in enumerate(TICKERS):\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"Processing Ticker {i+1}/{len(TICKERS)}: {ticker}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    status = \"Failed\"\n",
        "    message = \"\"\n",
        "\n",
        "    try:\n",
        "        # Define a clean filename\n",
        "        safe_ticker_name = ticker.replace('^', '').replace('=X', '').replace('=F', '').replace('-','_')\n",
        "        filename = f\"{OUTPUT_FILENAME_PREFIX}_{safe_ticker_name}.parquet\"\n",
        "\n",
        "        # --- Part 1: Data Acquisition ---\n",
        "        print(f\"Fetching data...\")\n",
        "        data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
        "\n",
        "        if data.empty:\n",
        "            message = \"No data returned for this ticker in the specified date range.\"\n",
        "            print(f\"‚ö†Ô∏è {message} Skipping.\")\n",
        "            results_summary.append({'Ticker': ticker, 'Status': 'Skipped', 'Details': message})\n",
        "            continue\n",
        "\n",
        "        # --- Part 2: Processing and Saving ---\n",
        "        data['currency'] = TICKER_INFO[ticker]['currency']\n",
        "        data['volume_unit'] = TICKER_INFO[ticker]['volume_unit']\n",
        "\n",
        "        data.reset_index(inplace=True)\n",
        "        data.rename(columns={'Date': 'date', 'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Adj Close': 'adj_close', 'Volume': 'volume'}, inplace=True)\n",
        "        data['date'] = pd.to_datetime(data['date']).dt.date\n",
        "\n",
        "        column_order = ['date', 'open', 'high', 'low', 'close', 'volume', 'currency', 'volume_unit', 'adj_close']\n",
        "        final_columns = [col for col in column_order if col in data.columns]\n",
        "        data = data[final_columns]\n",
        "\n",
        "        data.to_parquet(filename, index=False)\n",
        "        print(f\"‚úÖ Successfully saved data to '{filename}'\")\n",
        "\n",
        "        # --- Part 3: Verification & Reporting ---\n",
        "        first_date = data['date'].min()\n",
        "        last_date = data['date'].max()\n",
        "        row_count = len(data)\n",
        "\n",
        "        print(f\"üìà Data available from {first_date} to {last_date} ({row_count} rows).\")\n",
        "\n",
        "        # Display a sample of the data (first 5 rows)\n",
        "        print(f\"\\n--- Data Sample ---\")\n",
        "        print(tabulate(data.head(), headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "        status = \"Success\"\n",
        "        message = f\"{row_count} rows | {first_date} to {last_date}\"\n",
        "        results_summary.append({'Ticker': ticker, 'Status': status, 'Details': message})\n",
        "\n",
        "    except Exception as e:\n",
        "        message = f\"An error occurred: {e}\"\n",
        "        print(f\"‚ùå {message}\")\n",
        "        results_summary.append({'Ticker': ticker, 'Status': status, 'Details': message})\n",
        "\n",
        "    finally:\n",
        "        # --- Part 4: The \"Polite Wait\" ---\n",
        "        print(f\"\\nWaiting for {WAIT_TIME_SECONDS} seconds...\")\n",
        "        time.sleep(WAIT_TIME_SECONDS)\n",
        "\n",
        "# --- Part 5: Final Summary ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä Final Verification Summary\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "summary_df = pd.DataFrame(results_summary)\n",
        "print(tabulate(summary_df, headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "print(\"\\nüéâ All tickers processed. Long-term data acquisition complete.\")"
      ],
      "metadata": {
        "id": "A-Qckt4vuJdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install all required libraries\n",
        "!pip install yfinance tabulate pyswisseph\n",
        "\n",
        "# Step 2: Import all necessary libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from tabulate import tabulate\n",
        "import time\n",
        "import os\n",
        "import swisseph as swe\n",
        "from google.colab import drive\n",
        "\n",
        "# --- Part 1: Setup Google Drive and Folder Structure ---\n",
        "\n",
        "print(\"üìÇ Setting up Google Drive and project folders...\")\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Define the base path for your project in Google Drive\n",
        "    BASE_PATH = '/content/drive/MyDrive/AstroFinanceProject'\n",
        "    FINANCIAL_DATA_PATH = os.path.join(BASE_PATH, 'financial_data')\n",
        "    ASTRO_DATA_PATH = os.path.join(BASE_PATH, 'astro_data')\n",
        "\n",
        "    # Create the directories if they don't exist\n",
        "    os.makedirs(FINANCIAL_DATA_PATH, exist_ok=True)\n",
        "    os.makedirs(ASTRO_DATA_PATH, exist_ok=True)\n",
        "\n",
        "    print(f\"‚úÖ Project folders are ready in: {BASE_PATH}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Could not mount Google Drive. Error: {e}\")\n",
        "    # Exit if drive mounting fails, as we can't save files.\n",
        "    exit()\n",
        "\n",
        "# --- Part 2: Fetch and Save ALL Financial Data ---\n",
        "\n",
        "# Configuration for all tickers\n",
        "TICKER_INFO = {\n",
        "    # Indian Markets (Indices)\n",
        "    '^NSEI':                {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY 50\n",
        "    '^NSEBANK':             {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY BANK\n",
        "    'NIFTY_FIN_SERVICE.NS': {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY FINANCIAL SERVICES\n",
        "    '^CNXIT':               {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY IT\n",
        "    '^CNXPHARMA':           {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY PHARMA\n",
        "    '^CNXAUTO':             {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY AUTO\n",
        "    '^CNXMETAL':            {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY METAL\n",
        "    '^CNXFMCG':             {'currency': 'INR', 'volume_unit': 'shares'}, # NIFTY FMCG\n",
        "    '^INDIAVIX':            {'currency': 'INR', 'volume_unit': 'points'}, # India VIX\n",
        "\n",
        "    # Indian Markets (Key Stocks)\n",
        "    'RELIANCE.NS':          {'currency': 'INR', 'volume_unit': 'shares'}, # Reliance Industries\n",
        "    'TCS.NS':               {'currency': 'INR', 'volume_unit': 'shares'}, # Tata Consultancy Services\n",
        "    'HDFCBANK.NS':          {'currency': 'INR', 'volume_unit': 'shares'}, # HDFC Bank\n",
        "\n",
        "    # US Markets (Indices)\n",
        "    '^GSPC':        {'currency': 'USD', 'volume_unit': 'points'}, # S&P 500\n",
        "    '^DJI':         {'currency': 'USD', 'volume_unit': 'points'}, # Dow Jones Industrial Average\n",
        "    '^NDX':         {'currency': 'USD', 'volume_unit': 'points'}, # NASDAQ 100\n",
        "    '^RUT':         {'currency': 'USD', 'volume_unit': 'points'}, # Russell 2000 (Small-Cap)\n",
        "    '^VIX':         {'currency': 'USD', 'volume_unit': 'points'}, # CBOE Volatility Index\n",
        "    '^TNX':         {'currency': 'USD', 'volume_unit': 'points'}, # US 10-Yr Treasury Yield\n",
        "\n",
        "    # US Markets (Key Stocks)\n",
        "    'AAPL':         {'currency': 'USD', 'volume_unit': 'shares'}, # Apple Inc.\n",
        "    'MSFT':         {'currency': 'USD', 'volume_unit': 'shares'}, # Microsoft Corp.\n",
        "    'NVDA':         {'currency': 'USD', 'volume_unit': 'shares'}, # NVIDIA Corp.\n",
        "\n",
        "    # Global Markets (Indices)\n",
        "    '^N225':        {'currency': 'JPY', 'volume_unit': 'points'}, # Nikkei 225 (Japan)\n",
        "    '^FTSE':        {'currency': 'GBP', 'volume_unit': 'points'}, # FTSE 100 (UK)\n",
        "    '^GDAXI':       {'currency': 'EUR', 'volume_unit': 'points'}, # DAX (Germany)\n",
        "    '000001.SS':    {'currency': 'CNY', 'volume_unit': 'shares'}, # SSE Composite (Shanghai)\n",
        "    '^HSI':         {'currency': 'HKD', 'volume_unit': 'points'}, # Hang Seng (Hong Kong)\n",
        "\n",
        "    # Commodities\n",
        "    'GC=F':         {'currency': 'USD', 'volume_unit': 'contracts'}, # Gold\n",
        "    'CL=F':         {'currency': 'USD', 'volume_unit': 'contracts'}, # Crude Oil\n",
        "    'SI=F':         {'currency': 'USD', 'volume_unit': 'contracts'}, # Silver\n",
        "\n",
        "    # Currencies & DXY\n",
        "    'DX-Y.NYB':     {'currency': 'USD', 'volume_unit': 'points'},    # US Dollar Index\n",
        "    'USDINR=X':     {'currency': 'INR', 'volume_unit': 'rate'},\n",
        "    'EURUSD=X':     {'currency': 'USD', 'volume_unit': 'rate'},\n",
        "}\n",
        "\n",
        "TICKERS = list(TICKER_INFO.keys())\n",
        "START_DATE = '2000-01-01'\n",
        "END_DATE = datetime.now().strftime('%Y-%m-%d')\n",
        "WAIT_TIME_SECONDS = 1\n",
        "financial_results_summary = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"üìà Starting financial data acquisition for {len(TICKERS)} tickers...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, ticker in enumerate(TICKERS):\n",
        "    print(f\"\\n--- Processing Ticker {i+1}/{len(TICKERS)}: {ticker} ---\")\n",
        "    try:\n",
        "        safe_ticker_name = ticker.replace('^', '').replace('=X', '').replace('=F', '').replace('-','_').replace('.','_')\n",
        "        filename = os.path.join(FINANCIAL_DATA_PATH, f\"financial_data_{safe_ticker_name}.parquet\")\n",
        "\n",
        "        data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
        "\n",
        "        if data.empty:\n",
        "            message = \"No data returned in date range.\"\n",
        "            print(f\"‚ö†Ô∏è {message} Skipping.\")\n",
        "            financial_results_summary.append({'Ticker': ticker, 'Status': 'Skipped', 'Details': message})\n",
        "            continue\n",
        "\n",
        "        data['currency'] = TICKER_INFO[ticker]['currency']\n",
        "        data['volume_unit'] = TICKER_INFO[ticker]['volume_unit']\n",
        "        data.reset_index(inplace=True)\n",
        "        data.rename(columns={'Date': 'date', 'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Adj Close': 'adj_close', 'Volume': 'volume'}, inplace=True)\n",
        "        data['date'] = pd.to_datetime(data['date']).dt.date\n",
        "        column_order = ['date', 'open', 'high', 'low', 'close', 'volume', 'currency', 'volume_unit', 'adj_close']\n",
        "        final_columns = [col for col in column_order if col in data.columns]\n",
        "        data = data[final_columns]\n",
        "        data.to_parquet(filename, index=False)\n",
        "\n",
        "        first_date, last_date, row_count = data['date'].min(), data['date'].max(), len(data)\n",
        "        message = f\"{row_count} rows | {first_date} to {last_date}\"\n",
        "        print(f\"‚úÖ Saved to Drive. {message}\")\n",
        "        financial_results_summary.append({'Ticker': ticker, 'Status': 'Success', 'Details': message})\n",
        "\n",
        "    except Exception as e:\n",
        "        message = f\"Error: {e}\"\n",
        "        print(f\"‚ùå {message}\")\n",
        "        financial_results_summary.append({'Ticker': ticker, 'Status': 'Failed', 'Details': message})\n",
        "\n",
        "    finally:\n",
        "        time.sleep(WAIT_TIME_SECONDS)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä Financial Data Verification Summary\")\n",
        "print(\"=\"*60)\n",
        "summary_df = pd.DataFrame(financial_results_summary)\n",
        "print(tabulate(summary_df, headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "print(\"\\nüéâüéâüéâ Phase 1 - Financial Data Generation Complete! üéâüéâüéâ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKK7JHfU9a2w",
        "outputId": "490d9c71-24d2-4a2c-8514-5219ef1d5453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pyswisseph in /usr/local/lib/python3.12/dist-packages (2.10.3.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "üìÇ Setting up Google Drive and project folders...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Project folders are ready in: /content/drive/MyDrive/AstroFinanceProject\n",
            "\n",
            "============================================================\n",
            "üìà Starting financial data acquisition for 32 tickers...\n",
            "============================================================\n",
            "\n",
            "--- Processing Ticker 1/32: ^NSEI ---\n",
            "‚úÖ Saved to Drive. 4442 rows | 2007-09-17 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 2/32: ^NSEBANK ---\n",
            "‚úÖ Saved to Drive. 4167 rows | 2007-09-17 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 3/32: NIFTY_FIN_SERVICE.NS ---\n",
            "‚úÖ Saved to Drive. 3465 rows | 2011-09-07 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 4/32: ^CNXIT ---\n",
            "‚úÖ Saved to Drive. 4152 rows | 2007-09-17 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 5/32: ^CNXPHARMA ---\n",
            "‚úÖ Saved to Drive. 3630 rows | 2011-01-31 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 6/32: ^CNXAUTO ---\n",
            "‚úÖ Saved to Drive. 3504 rows | 2011-07-12 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 7/32: ^CNXMETAL ---\n",
            "‚úÖ Saved to Drive. 3504 rows | 2011-07-12 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 8/32: ^CNXFMCG ---\n",
            "‚úÖ Saved to Drive. 3615 rows | 2011-01-31 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 9/32: ^INDIAVIX ---\n",
            "‚úÖ Saved to Drive. 4324 rows | 2008-03-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 10/32: RELIANCE.NS ---\n",
            "‚úÖ Saved to Drive. 6440 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 11/32: TCS.NS ---\n",
            "‚úÖ Saved to Drive. 5761 rows | 2002-08-12 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 12/32: HDFCBANK.NS ---\n",
            "‚úÖ Saved to Drive. 6443 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 13/32: ^GSPC ---\n",
            "‚úÖ Saved to Drive. 6494 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 14/32: ^DJI ---\n",
            "‚úÖ Saved to Drive. 6494 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 15/32: ^NDX ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved to Drive. 6494 rows | 2000-01-03 to 2025-10-27\n",
            "\n",
            "--- Processing Ticker 16/32: ^RUT ---\n",
            "‚úÖ Saved to Drive. 6494 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 17/32: ^VIX ---\n",
            "‚úÖ Saved to Drive. 6494 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 18/32: ^TNX ---\n",
            "‚úÖ Saved to Drive. 6488 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 19/32: AAPL ---\n",
            "‚úÖ Saved to Drive. 6494 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 20/32: MSFT ---\n",
            "‚úÖ Saved to Drive. 6494 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 21/32: NVDA ---\n",
            "‚úÖ Saved to Drive. 6494 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 22/32: ^N225 ---\n",
            "‚úÖ Saved to Drive. 6325 rows | 2000-01-04 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 23/32: ^FTSE ---\n",
            "‚úÖ Saved to Drive. 6522 rows | 2000-01-04 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 24/32: ^GDAXI ---\n",
            "‚úÖ Saved to Drive. 6558 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 25/32: 000001.SS ---\n",
            "‚úÖ Saved to Drive. 6248 rows | 2000-01-04 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 26/32: ^HSI ---\n",
            "‚úÖ Saved to Drive. 6362 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 27/32: GC=F ---\n",
            "‚úÖ Saved to Drive. 6313 rows | 2000-08-30 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 28/32: CL=F ---\n",
            "‚úÖ Saved to Drive. 6322 rows | 2000-08-23 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 29/32: SI=F ---\n",
            "‚úÖ Saved to Drive. 6315 rows | 2000-08-30 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 30/32: DX-Y.NYB ---\n",
            "‚úÖ Saved to Drive. 6523 rows | 2000-01-03 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 31/32: USDINR=X ---\n",
            "‚úÖ Saved to Drive. 5681 rows | 2003-12-01 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Ticker 32/32: EURUSD=X ---\n",
            "‚úÖ Saved to Drive. 5684 rows | 2003-12-01 to 2025-10-27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1094038738.py:103: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìä Financial Data Verification Summary\n",
            "============================================================\n",
            "+----------------------+----------+--------------------------------------+\n",
            "| Ticker               | Status   | Details                              |\n",
            "|----------------------+----------+--------------------------------------|\n",
            "| ^NSEI                | Success  | 4442 rows | 2007-09-17 to 2025-10-27 |\n",
            "| ^NSEBANK             | Success  | 4167 rows | 2007-09-17 to 2025-10-27 |\n",
            "| NIFTY_FIN_SERVICE.NS | Success  | 3465 rows | 2011-09-07 to 2025-10-27 |\n",
            "| ^CNXIT               | Success  | 4152 rows | 2007-09-17 to 2025-10-27 |\n",
            "| ^CNXPHARMA           | Success  | 3630 rows | 2011-01-31 to 2025-10-27 |\n",
            "| ^CNXAUTO             | Success  | 3504 rows | 2011-07-12 to 2025-10-27 |\n",
            "| ^CNXMETAL            | Success  | 3504 rows | 2011-07-12 to 2025-10-27 |\n",
            "| ^CNXFMCG             | Success  | 3615 rows | 2011-01-31 to 2025-10-27 |\n",
            "| ^INDIAVIX            | Success  | 4324 rows | 2008-03-03 to 2025-10-27 |\n",
            "| RELIANCE.NS          | Success  | 6440 rows | 2000-01-03 to 2025-10-27 |\n",
            "| TCS.NS               | Success  | 5761 rows | 2002-08-12 to 2025-10-27 |\n",
            "| HDFCBANK.NS          | Success  | 6443 rows | 2000-01-03 to 2025-10-27 |\n",
            "| ^GSPC                | Success  | 6494 rows | 2000-01-03 to 2025-10-27 |\n",
            "| ^DJI                 | Success  | 6494 rows | 2000-01-03 to 2025-10-27 |\n",
            "| ^NDX                 | Success  | 6494 rows | 2000-01-03 to 2025-10-27 |\n",
            "| ^RUT                 | Success  | 6494 rows | 2000-01-03 to 2025-10-27 |\n",
            "| ^VIX                 | Success  | 6494 rows | 2000-01-03 to 2025-10-27 |\n",
            "| ^TNX                 | Success  | 6488 rows | 2000-01-03 to 2025-10-27 |\n",
            "| AAPL                 | Success  | 6494 rows | 2000-01-03 to 2025-10-27 |\n",
            "| MSFT                 | Success  | 6494 rows | 2000-01-03 to 2025-10-27 |\n",
            "| NVDA                 | Success  | 6494 rows | 2000-01-03 to 2025-10-27 |\n",
            "| ^N225                | Success  | 6325 rows | 2000-01-04 to 2025-10-27 |\n",
            "| ^FTSE                | Success  | 6522 rows | 2000-01-04 to 2025-10-27 |\n",
            "| ^GDAXI               | Success  | 6558 rows | 2000-01-03 to 2025-10-27 |\n",
            "| 000001.SS            | Success  | 6248 rows | 2000-01-04 to 2025-10-27 |\n",
            "| ^HSI                 | Success  | 6362 rows | 2000-01-03 to 2025-10-27 |\n",
            "| GC=F                 | Success  | 6313 rows | 2000-08-30 to 2025-10-27 |\n",
            "| CL=F                 | Success  | 6322 rows | 2000-08-23 to 2025-10-27 |\n",
            "| SI=F                 | Success  | 6315 rows | 2000-08-30 to 2025-10-27 |\n",
            "| DX-Y.NYB             | Success  | 6523 rows | 2000-01-03 to 2025-10-27 |\n",
            "| USDINR=X             | Success  | 5681 rows | 2003-12-01 to 2025-10-27 |\n",
            "| EURUSD=X             | Success  | 5684 rows | 2003-12-01 to 2025-10-27 |\n",
            "+----------------------+----------+--------------------------------------+\n",
            "\n",
            "üéâüéâüéâ Phase 1 - Financial Data Generation Complete! üéâüéâüéâ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# This script is for Cell 2.\n",
        "# It assumes Cell 1 has been run and Google Drive is mounted.\n",
        "# It installs its own dependencies and generates the astrological data.\n",
        "# ---\n",
        "\n",
        "# Step 1: Install required libraries\n",
        "# We do NOT need swisseph-data, as we will download the files manually\n",
        "!pip install pandas tabulate pyswisseph\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from tabulate import tabulate\n",
        "import os\n",
        "import swisseph as swe\n",
        "# We no longer import swisseph_data\n",
        "from google.colab import drive\n",
        "\n",
        "# Step 3: Define constants (in sync with Cell 1)\n",
        "BASE_PATH = '/content/drive/MyDrive/AstroFinanceProject'\n",
        "ASTRO_DATA_PATH = os.path.join(BASE_PATH, 'astro_data')\n",
        "# This is our new, manually downloaded data folder\n",
        "EPHE_DOWNLOAD_PATH = os.path.join(ASTRO_DATA_PATH, 'ephe')\n",
        "START_DATE = '2000-01-01'\n",
        "# This ensures the month is correctly formatted as a number (e.g., '10')\n",
        "END_DATE = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "# --- Part 3: Generate Vedic Astrological Ephemeris Data ---\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üî≠ Generating Vedic astrological ephemeris data (2000-Today)...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# --- NEW ROBUST APPROACH: Download and Unzip Master File ---\n",
        "\n",
        "# Create the target directory if it doesn't exist\n",
        "os.makedirs(EPHE_DOWNLOAD_PATH, exist_ok=True)\n",
        "\n",
        "# Check for a key planetary file. If it's missing, download and unzip the master file.\n",
        "check_file = os.path.join(EPHE_DOWNLOAD_PATH, 'seplm00.se1')\n",
        "if not os.path.exists(check_file):\n",
        "    print(f\"Essential ephemeris file ({os.path.basename(check_file)}) not found.\")\n",
        "\n",
        "    # Define the ZIP file URL and local save path\n",
        "    EPHE_ZIP_URL = 'https://www.astro.ch/ftp/swisseph/ephe.zip'\n",
        "    EPHE_ZIP_PATH = os.path.join(ASTRO_DATA_PATH, 'ephe.zip') # Save zip one level up\n",
        "\n",
        "    print(f\"Downloading 'ephe.zip' (~111 MB) from {EPHE_ZIP_URL}...\")\n",
        "    print(\"This may take a minute, but only needs to run once.\")\n",
        "\n",
        "    # Download the single zip file\n",
        "    !wget -q -O {EPHE_ZIP_PATH} {EPHE_ZIP_URL}\n",
        "\n",
        "    print(\"Download complete. Unzipping...\")\n",
        "\n",
        "    # Unzip the file into the target 'ephe' directory\n",
        "    # -o: overwrite existing files without prompting\n",
        "    # -d: destination directory\n",
        "    # -qq: quiet mode (less verbose)\n",
        "    !unzip -o -qq {EPHE_ZIP_PATH} -d {EPHE_DOWNLOAD_PATH}\n",
        "\n",
        "    print(\"Unzip complete. Deleting zip file to save space...\")\n",
        "    !rm {EPHE_ZIP_PATH}\n",
        "\n",
        "    print(\"‚úÖ Ephemeris files are ready.\")\n",
        "else:\n",
        "    print(f\"Essential ephemeris files already exist in {EPHE_DOWNLOAD_PATH}.\")\n",
        "\n",
        "\n",
        "# Set the ephemeris data path to our new downloaded folder\n",
        "try:\n",
        "    swe.set_ephe_path(EPHE_DOWNLOAD_PATH)\n",
        "    print(f\"Ephemeris data path set to: {EPHE_DOWNLOAD_PATH}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå CRITICAL ERROR: Could not set ephemeris data path. {e}\")\n",
        "    exit()\n",
        "\n",
        "# Set to Lahiri Ayanamsha for Vedic astrology\n",
        "swe.set_sid_mode(swe.SIDM_LAHIRI)\n",
        "\n",
        "PLANETS = {\n",
        "    'SUN': swe.SUN,\n",
        "    'MOON': swe.MOON,\n",
        "    'MERCURY': swe.MERCURY,\n",
        "    'VENUS': swe.VENUS,\n",
        "    'MARS': swe.MARS,\n",
        "    'JUPITER': swe.JUPITER,\n",
        "    'SATURN': swe.SATURN,\n",
        "    'RAHU': swe.MEAN_NODE # Rahu (Mean North Node)\n",
        "}\n",
        "\n",
        "date_range = pd.date_range(start=START_DATE, end=END_DATE, freq='D')\n",
        "astro_data = []\n",
        "error_printed = False\n",
        "\n",
        "for date in date_range:\n",
        "    julian_day = swe.utc_to_jd(date.year, date.month, date.day, 0, 0, 0, 1)[0]\n",
        "    daily_positions = {'date': date.date()}\n",
        "\n",
        "    for name, planet_id in PLANETS.items():\n",
        "        pos = swe.calc_ut(julian_day, planet_id)\n",
        "\n",
        "        # Check if calculation was successful\n",
        "        if isinstance(pos[0], float):\n",
        "            daily_positions[f'{name}_lon'] = pos[0]\n",
        "            daily_positions[f'{name}_speed'] = pos[3]\n",
        "        else:\n",
        "            # Store nulls on failure\n",
        "            daily_positions[f'{name}_lon'] = None\n",
        "            daily_positions[f'{name}_speed'] = None\n",
        "            if not error_printed:\n",
        "                print(f\"‚ö†Ô∏è Warning: Could not calculate a position on {date.date()}. Storing null. This message will not repeat.\")\n",
        "                error_printed = True\n",
        "\n",
        "    astro_data.append(daily_positions)\n",
        "\n",
        "astro_df = pd.DataFrame(astro_data)\n",
        "\n",
        "# Verification check\n",
        "if astro_df.empty:\n",
        "    print(\"\\n\" + \"!\"*60)\n",
        "    print(\"‚ùå ERROR: The astrological DataFrame is empty.\")\n",
        "    print(\"Please check your START_DATE and END_DATE variables.\")\n",
        "    print(\"!\"*60)\n",
        "else:\n",
        "    # Ensure the save directory exists (it should from above, but good to check)\n",
        "    os.makedirs(ASTRO_DATA_PATH, exist_ok=True)\n",
        "\n",
        "    astro_filename = os.path.join(ASTRO_DATA_PATH, 'vedic_ephemeris_2000_today.parquet')\n",
        "    astro_df.to_parquet(astro_filename, index=False)\n",
        "\n",
        "    print(f\"‚úÖ Successfully saved astrological data to '{astro_filename}'\")\n",
        "    print(f\"üìà Total days processed: {len(astro_df)}\")\n",
        "\n",
        "    print(\"\\n--- Astrological Data Sample ---\")\n",
        "    if astro_df.head().empty:\n",
        "         print(\"WARNING: DataFrame was saved, but the first 5 rows (head) are empty.\")\n",
        "    elif astro_df.iloc[0].isnull().all():\n",
        "         print(\"WARNING: DataFrame was saved, but the first row is all null values. Calculations are likely failing.\")\n",
        "         print(tabulate(astro_df.head(), headers='keys', tablefmt='psql', showindex=False))\n",
        "    else:\n",
        "         print(tabulate(astro_df.head(), headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "print(\"\\nüéâüéâüéâ Phase 1 - Astrological Data Generation Complete! üéâüéâüéâ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acbYT15QGBfu",
        "outputId": "65c64ff0-328c-4899-b00c-5136361151c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pyswisseph in /usr/local/lib/python3.12/dist-packages (2.10.3.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\n",
            "============================================================\n",
            "üî≠ Generating Vedic astrological ephemeris data (2000-Today)...\n",
            "============================================================\n",
            "Essential ephemeris file (seplm00.se1) not found.\n",
            "Downloading 'ephe.zip' (~111 MB) from https://www.astro.ch/ftp/swisseph/ephe.zip...\n",
            "This may take a minute, but only needs to run once.\n",
            "Download complete. Unzipping...\n",
            "[/content/drive/MyDrive/AstroFinanceProject/astro_data/ephe.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/drive/MyDrive/AstroFinanceProject/astro_data/ephe.zip or\n",
            "        /content/drive/MyDrive/AstroFinanceProject/astro_data/ephe.zip.zip, and cannot find /content/drive/MyDrive/AstroFinanceProject/astro_data/ephe.zip.ZIP, period.\n",
            "Unzip complete. Deleting zip file to save space...\n",
            "‚úÖ Ephemeris files are ready.\n",
            "Ephemeris data path set to: /content/drive/MyDrive/AstroFinanceProject/astro_data/ephe\n",
            "‚ö†Ô∏è Warning: Could not calculate a position on 2000-01-01. Storing null. This message will not repeat.\n",
            "‚úÖ Successfully saved astrological data to '/content/drive/MyDrive/AstroFinanceProject/astro_data/vedic_ephemeris_2000_today.parquet'\n",
            "üìà Total days processed: 9433\n",
            "\n",
            "--- Astrological Data Sample ---\n",
            "+------------+-----------+-------------+------------+--------------+---------------+-----------------+-------------+---------------+------------+--------------+---------------+-----------------+--------------+----------------+------------+--------------+\n",
            "| date       | SUN_lon   | SUN_speed   | MOON_lon   | MOON_speed   | MERCURY_lon   | MERCURY_speed   | VENUS_lon   | VENUS_speed   | MARS_lon   | MARS_speed   | JUPITER_lon   | JUPITER_speed   | SATURN_lon   | SATURN_speed   | RAHU_lon   | RAHU_speed   |\n",
            "|------------+-----------+-------------+------------+--------------+---------------+-----------------+-------------+---------------+------------+--------------+---------------+-----------------+--------------+----------------+------------+--------------|\n",
            "| 2000-01-01 |           |             |            |              |               |                 |             |               |            |              |               |                 |              |                |            |              |\n",
            "| 2000-01-02 |           |             |            |              |               |                 |             |               |            |              |               |                 |              |                |            |              |\n",
            "| 2000-01-03 |           |             |            |              |               |                 |             |               |            |              |               |                 |              |                |            |              |\n",
            "| 2000-01-04 |           |             |            |              |               |                 |             |               |            |              |               |                 |              |                |            |              |\n",
            "| 2000-01-05 |           |             |            |              |               |                 |             |               |            |              |               |                 |              |                |            |              |\n",
            "+------------+-----------+-------------+------------+--------------+---------------+-----------------+-------------+---------------+------------+--------------+---------------+-----------------+--------------+----------------+------------+--------------+\n",
            "\n",
            "üéâüéâüéâ Phase 1 - Astrological Data Generation Complete! üéâüéâüéâ\n"
          ]
        }
      ]
    }
  ]
}